{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat or Dog?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using neural networks to determine if an image contains a cat or a dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to make a image classification model tha can determine if an image contains a cat or a dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN/ convolutional neural net: A model that tries to observe patterns in an array/image and then use those patterns to identify classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was taken from an old kaggle competition that can be found [here](https://www.kaggle.com/c/dogs-vs-cats). The images are from an old CAPTCHA known as *Animal Species Image Recognition for Restricting Access* (or *Asirra* for short) which asked the user to identify whether or not several images displayed contained either a cat or a dog.\n",
    "\n",
    "There are 25,000 images total evenly split between cats(0) and dogs(1). \n",
    "\n",
    "The train and validation data were organized and divided up as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(data_path)\n",
    "labels = \\[\\]\n",
    "\n",
    "for filename in filenames:\n",
    "    label = filename.split('.')\\[0\\]\n",
    "    if label == 'dog':\n",
    "        labels.append(1) #1 for dog\n",
    "    else:\n",
    "        labels.append(0) #0 for cat\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "X_t, v_t = train_test_split(df, test_size = 0.15,  random_state = 7)\n",
    "X_t = X_t.reset_index(drop = True)\n",
    "v_t = v_t.reset_index(drop=True)\n",
    "\n",
    "#X_t is the training data and v_t is the validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a grasp on the rough size of the images to create a better target size for my models I had made this script to get the average height and width of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "width = []\n",
    "height = []\n",
    "\n",
    "for filename in filenames:\n",
    "    \n",
    "\n",
    "    \n",
    "    img_path = os.path.join(data_path, filename)\n",
    "    im = Image.open(img_path)\n",
    "    \n",
    "    w, h = im.size\n",
    "    \n",
    "    width.append(w)\n",
    "    height.append(h)\n",
    "    \n",
    "w_avg = sum(width)/len(width)\n",
    "h_avg = sum(height)/len(height)\n",
    "    \n",
    "print(w_avg, h_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returned (404, 360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All modeling was done using CNN's with convolutional and dense layers. Dropout layers were used to avoid overfitting. Accuracy score was the evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this time I was not aware that I'd made an error with the average image size (which I was using as the target size). The first script only grabbed the dimensions of the last image in the diretcory, this error is addresed in the 'Modeling' notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator(rescale = 1./255., horizontal_flip = True) \n",
    "\n",
    "train_generator = img_gen.flow_from_dataframe(\n",
    "    X_t,\n",
    "    data_path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size = (499, 375), \n",
    "    batch_size = batch_size,\n",
    "    class_mode ='categorical'\n",
    ")\n",
    "\n",
    "val_img_gen = ImageDataGenerator(rescale = 1./255.) \n",
    "\n",
    "val_generator = img_gen.flow_from_dataframe(\n",
    "    v_t,\n",
    "    data_path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size = (499, 375), \n",
    "    batch_size = batch_size,\n",
    "    class_mode ='categorical'\n",
    ")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "\n",
    "fsm = Sequential() \n",
    "fsm.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (width, height, 3)))#3 for rgb\n",
    "fsm.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "fsm.add(BatchNormalization())\n",
    "fsm.add(Dropout(0.20))\n",
    "\n",
    "fsm.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "fsm.add(MaxPooling2D((2, 2)))\n",
    "fsm.add(BatchNormalization())\n",
    "fsm.add(Dropout(0.20))\n",
    "\n",
    "fsm.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "fsm.add(MaxPooling2D((2, 2)))\n",
    "fsm.add(BatchNormalization())\n",
    "fsm.add(Dropout(0.20))\n",
    "\n",
    "fsm.add(Flatten())\n",
    "fsm.add(Dense(64, activation='relu'))\n",
    "fsm.add(BatchNormalization())\n",
    "fsm.add(Dropout(0.20))\n",
    "\n",
    "fsm.add(Dense(128, activation='relu'))\n",
    "fsm.add(BatchNormalization())\n",
    "fsm.add(Dropout(0.20))\n",
    "\n",
    "fsm.add(Dense(2, activation='softmax')) #2 for cat or dog \n",
    "fsm.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *IMAGE HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses the actual average image height and width and all the values of the conv2d and dense layers were doubled to make them more able to extract features and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator(rescale = 1./255., horizontal_flip = True)\n",
    "\n",
    "train_generator = img_gen.flow_from_dataframe(\n",
    "    X_t,\n",
    "    data_path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size = img_size,#\n",
    "    batch_size = batch_size,\n",
    "    class_mode ='categorical'\n",
    ")\n",
    "\n",
    "val_img_gen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "val_generator = img_gen.flow_from_dataframe(\n",
    "    v_t,\n",
    "    data_path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode ='categorical'\n",
    ")\n",
    "\n",
    "alpha = Sequential() \n",
    "alpha.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (width, height, 3)))#3 for rgb\n",
    "alpha.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "alpha.add(BatchNormalization())\n",
    "alpha.add(Dropout(0.20))\n",
    "\n",
    "alpha.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "alpha.add(MaxPooling2D((2, 2)))\n",
    "alpha.add(BatchNormalization())\n",
    "alpha.add(Dropout(0.20))\n",
    "\n",
    "alpha.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "alpha.add(MaxPooling2D((2, 2)))\n",
    "alpha.add(BatchNormalization())\n",
    "alpha.add(Dropout(0.20))\n",
    "\n",
    "alpha.add(Conv2D(256, (3, 3), activation = 'relu'))\n",
    "alpha.add(MaxPooling2D((2, 2)))\n",
    "alpha.add(BatchNormalization())\n",
    "alpha.add(Dropout(0.20))\n",
    "\n",
    "alpha.add(Flatten())\n",
    "alpha.add(Dense(128, activation='relu'))\n",
    "alpha.add(BatchNormalization())\n",
    "alpha.add(Dropout(0.20))\n",
    "\n",
    "alpha.add(Dense(256, activation='relu'))\n",
    "alpha.add(BatchNormalization())\n",
    "alpha.add(Dropout(0.20))\n",
    "\n",
    "alpha.add(Dense(2, activation='softmax')) #2 for cat or dog\n",
    "alpha.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "alpha.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *IMAGE HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (256, 256)\n",
    "\n",
    "train_generator = img_gen.flow_from_dataframe(\n",
    "    X_t,\n",
    "    data_path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode ='categorical'\n",
    ")\n",
    "\n",
    "val_img_gen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "val_generator = img_gen.flow_from_dataframe(\n",
    "    v_t,\n",
    "    data_path,\n",
    "    x_col = 'filename',\n",
    "    y_col = 'label',\n",
    "    target_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode ='categorical'\n",
    ")\n",
    "\n",
    "delta = Sequential() \n",
    "delta.add(Conv2D(32, (3, 3), activation = 'relu', input_shape = (256, 256, 3)))#3 for rgb\n",
    "delta.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "delta.add(BatchNormalization())\n",
    "delta.add(Dropout(0.20))\n",
    "\n",
    "delta.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "delta.add(MaxPooling2D((2, 2)))\n",
    "delta.add(BatchNormalization())\n",
    "delta.add(Dropout(0.20))\n",
    "\n",
    "delta.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "delta.add(MaxPooling2D((2, 2)))\n",
    "delta.add(BatchNormalization())\n",
    "delta.add(Dropout(0.20))\n",
    "\n",
    "delta.add(Conv2D(256, (3, 3), activation = 'relu'))\n",
    "delta.add(MaxPooling2D((2, 2)))\n",
    "delta.add(BatchNormalization())\n",
    "delta.add(Dropout(0.20))\n",
    "\n",
    "delta.add(Flatten())\n",
    "delta.add(Dense(128, activation='relu'))\n",
    "delta.add(BatchNormalization())\n",
    "delta.add(Dropout(0.20))\n",
    "\n",
    "delta.add(Dense(256, activation='relu'))\n",
    "delta.add(BatchNormalization())\n",
    "delta.add(Dropout(0.20))\n",
    "\n",
    "delta.add(Dense(2, activation='softmax')) #2 for cat or dog\n",
    "delta.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *IMAGE HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may come as a suprise but the best performing model was alpha, despite the lower accuracy score than delta. Here's why:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While delta performed better what cannot be ignored is that delta labeled more images as 'cat' or 0 and is therefor biased towards that class, while 'dog' or 1 was under represented. With alpha it may have a lower accuracy score but it does not show any signifigant evidence of bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that there is no evidence of a test set being used. As this is a kaggle competition there was a test set but the images were not labeled. In the future I will grab 100-200 images from the unlabeled test set and manualy label them cat or dog to get a score out of 100-200 on its test accuracy to produce an accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
